{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedc7c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:27: SyntaxWarning: invalid escape sequence '\\&'\n",
      "<>:27: SyntaxWarning: invalid escape sequence '\\&'\n",
      "C:\\Users\\uah\\AppData\\Local\\Temp\\ipykernel_2152\\1210652897.py:27: SyntaxWarning: invalid escape sequence '\\&'\n",
      "  PLOT_TITLE = \"Electrostatic (EELEC) \\& Van der Waals (EVDW) Energy Analysis\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Processing 16 search configurations.\n",
      "\n",
      "================================================================================\n",
      "CONFIGURATION 1/16: Fe-FeGa_ARG_HEM\n",
      "================================================================================\n",
      "‚úÖ Found 1 files matching the condition.\n",
      "\n",
      "Files included in this group:\n",
      "    - _FE_lie_I_844_O_1483_BP_HH.csv\n",
      "--------------------------------------------------\n",
      "‚úÖ DataFrames from 1 files combined. Total rows: 6000.\n",
      "   ‚úÖ Final file generated: AND-HH_OR1-_FE___FEGA__OR2-104_844_OR3-1481_1483_STATS.csv\n",
      "\n",
      "================================================================================\n",
      "CONFIGURATION 2/16: Ga-GaFe_ARG_HEM\n",
      "================================================================================\n",
      "‚úÖ Found 1 files matching the condition.\n",
      "\n",
      "Files included in this group:\n",
      "    - _GAFE_lie_I_844_O_1483_BP_HH.csv\n",
      "--------------------------------------------------\n",
      "‚úÖ DataFrames from 1 files combined. Total rows: 6000.\n",
      "   ‚úÖ Final file generated: AND-HH_OR1-_GA___GAFE__OR2-104_844_OR3-1481_1483_STATS.csv\n",
      "\n",
      "================================================================================\n",
      "CONFIGURATION 3/16: Fe-FeGa_ARG_MET\n",
      "================================================================================\n",
      "‚úÖ Found 1 files matching the condition.\n",
      "\n",
      "Files included in this group:\n",
      "    - _FE_lie_I_844_O_1484_BP_HH.csv\n",
      "--------------------------------------------------\n",
      "‚úÖ DataFrames from 1 files combined. Total rows: 6000.\n",
      "   ‚úÖ Final file generated: AND-HH_OR1-_FE___FEGA__OR2-104_844_OR3-1482_1484_STATS.csv\n",
      "\n",
      "================================================================================\n",
      "CONFIGURATION 4/16: Ga-GaFe_ARG_MET\n",
      "================================================================================\n",
      "‚úÖ Found 1 files matching the condition.\n",
      "\n",
      "Files included in this group:\n",
      "    - _GAFE_lie_I_844_O_1484_BP_HH.csv\n",
      "--------------------------------------------------\n",
      "‚úÖ DataFrames from 1 files combined. Total rows: 6000.\n",
      "   ‚úÖ Final file generated: AND-HH_OR1-_GA___GAFE__OR2-104_844_OR3-1482_1484_STATS.csv\n",
      "\n",
      "================================================================================\n",
      "CONFIGURATION 5/16: Fe-FeGa_TRP_HEM\n",
      "================================================================================\n",
      "‚úÖ Found 1 files matching the condition.\n",
      "\n",
      "Files included in this group:\n",
      "    - _FE_lie_I_847_O_1483_BP_HH.csv\n",
      "--------------------------------------------------\n",
      "‚úÖ DataFrames from 1 files combined. Total rows: 6000.\n",
      "   ‚úÖ Final file generated: AND-HH_OR1-_FE___FEGA__OR2-107_847_OR3-1481_1483_STATS.csv\n",
      "\n",
      "================================================================================\n",
      "CONFIGURATION 6/16: Ga-GaFe_TRP_HEM\n",
      "================================================================================\n",
      "‚úÖ Found 1 files matching the condition.\n",
      "\n",
      "Files included in this group:\n",
      "    - _GAFE_lie_I_847_O_1483_BP_HH.csv\n",
      "--------------------------------------------------\n",
      "‚úÖ DataFrames from 1 files combined. Total rows: 6000.\n",
      "   ‚úÖ Final file generated: AND-HH_OR1-_GA___GAFE__OR2-107_847_OR3-1481_1483_STATS.csv\n",
      "\n",
      "================================================================================\n",
      "CONFIGURATION 7/16: Fe-FeGa_TRP_MET\n",
      "================================================================================\n",
      "‚úÖ Found 1 files matching the condition.\n",
      "\n",
      "Files included in this group:\n",
      "    - _FE_lie_I_847_O_1484_BP_HH.csv\n",
      "--------------------------------------------------\n",
      "‚úÖ DataFrames from 1 files combined. Total rows: 6000.\n",
      "   ‚úÖ Final file generated: AND-HH_OR1-_FE___FEGA__OR2-107_847_OR3-1482_1484_STATS.csv\n",
      "\n",
      "================================================================================\n",
      "CONFIGURATION 8/16: Ga-GaFe_TRP_MET\n",
      "================================================================================\n",
      "‚úÖ Found 1 files matching the condition.\n",
      "\n",
      "Files included in this group:\n",
      "    - _GAFE_lie_I_847_O_1484_BP_HH.csv\n",
      "--------------------------------------------------\n",
      "‚úÖ DataFrames from 1 files combined. Total rows: 6000.\n",
      "   ‚úÖ Final file generated: AND-HH_OR1-_GA___GAFE__OR2-107_847_OR3-1482_1484_STATS.csv\n",
      "\n",
      "================================================================================\n",
      "CONFIGURATION 9/16: Fe-FeGa_HIS-A_HEM\n",
      "================================================================================\n",
      "‚úÖ Found 1 files matching the condition.\n",
      "\n",
      "Files included in this group:\n",
      "    - _FE_lie_I_848_O_1483_BP_HH.csv\n",
      "--------------------------------------------------\n",
      "‚úÖ DataFrames from 1 files combined. Total rows: 6000.\n",
      "   ‚úÖ Final file generated: AND-HH_OR1-_FE___FEGA__OR2-108_848_OR3-1481_1483_STATS.csv\n",
      "\n",
      "================================================================================\n",
      "CONFIGURATION 10/16: Ga-GaFe_HIS-A_HEM\n",
      "================================================================================\n",
      "‚úÖ Found 1 files matching the condition.\n",
      "\n",
      "Files included in this group:\n",
      "    - _GAFE_lie_I_848_O_1483_BP_HH.csv\n",
      "--------------------------------------------------\n",
      "‚úÖ DataFrames from 1 files combined. Total rows: 6000.\n",
      "   ‚úÖ Final file generated: AND-HH_OR1-_GA___GAFE__OR2-108_848_OR3-1481_1483_STATS.csv\n",
      "\n",
      "================================================================================\n",
      "CONFIGURATION 11/16: Fe-FeGa_HIS-A_MET\n",
      "================================================================================\n",
      "‚úÖ Found 1 files matching the condition.\n",
      "\n",
      "Files included in this group:\n",
      "    - _FE_lie_I_848_O_1484_BP_HH.csv\n",
      "--------------------------------------------------\n",
      "‚úÖ DataFrames from 1 files combined. Total rows: 6000.\n",
      "   ‚úÖ Final file generated: AND-HH_OR1-_FE___FEGA__OR2-108_848_OR3-1482_1484_STATS.csv\n",
      "\n",
      "================================================================================\n",
      "CONFIGURATION 12/16: Ga-GaFe_HIS-A_MET\n",
      "================================================================================\n",
      "‚úÖ Found 1 files matching the condition.\n",
      "\n",
      "Files included in this group:\n",
      "    - _GAFE_lie_I_848_O_1484_BP_HH.csv\n",
      "--------------------------------------------------\n",
      "‚úÖ DataFrames from 1 files combined. Total rows: 6000.\n",
      "   ‚úÖ Final file generated: AND-HH_OR1-_GA___GAFE__OR2-108_848_OR3-1482_1484_STATS.csv\n",
      "\n",
      "================================================================================\n",
      "CONFIGURATION 13/16: Fe-FeGa_HIS-B_HEM\n",
      "================================================================================\n",
      "‚úÖ Found 1 files matching the condition.\n",
      "\n",
      "Files included in this group:\n",
      "    - _FE_lie_I_1010_O_1483_BP_HH.csv\n",
      "--------------------------------------------------\n",
      "‚úÖ DataFrames from 1 files combined. Total rows: 6000.\n",
      "   ‚úÖ Final file generated: AND-HH_OR1-_FE___FEGA__OR2-270_1010_OR3-1481_1483_STATS.csv\n",
      "\n",
      "================================================================================\n",
      "CONFIGURATION 14/16: Ga-GaFe_HIS-B_HEM\n",
      "================================================================================\n",
      "‚úÖ Found 1 files matching the condition.\n",
      "\n",
      "Files included in this group:\n",
      "    - _GAFE_lie_I_1010_O_1483_BP_HH.csv\n",
      "--------------------------------------------------\n",
      "‚úÖ DataFrames from 1 files combined. Total rows: 6000.\n",
      "   ‚úÖ Final file generated: AND-HH_OR1-_GA___GAFE__OR2-270_1010_OR3-1481_1483_STATS.csv\n",
      "\n",
      "================================================================================\n",
      "CONFIGURATION 15/16: Fe-FeGa_HIS-B_MET\n",
      "================================================================================\n",
      "‚úÖ Found 1 files matching the condition.\n",
      "\n",
      "Files included in this group:\n",
      "    - _FE_lie_I_1010_O_1484_BP_HH.csv\n",
      "--------------------------------------------------\n",
      "‚úÖ DataFrames from 1 files combined. Total rows: 6000.\n",
      "   ‚úÖ Final file generated: AND-HH_OR1-_FE___FEGA__OR2-270_1010_OR3-1482_1484_STATS.csv\n",
      "\n",
      "================================================================================\n",
      "CONFIGURATION 16/16: Ga-GaFe_HIS-B_MET\n",
      "================================================================================\n",
      "‚úÖ Found 1 files matching the condition.\n",
      "\n",
      "Files included in this group:\n",
      "    - _GAFE_lie_I_1010_O_1484_BP_HH.csv\n",
      "--------------------------------------------------\n",
      "‚úÖ DataFrames from 1 files combined. Total rows: 6000.\n",
      "   ‚úÖ Final file generated: AND-HH_OR1-_GA___GAFE__OR2-270_1010_OR3-1482_1484_STATS.csv\n",
      "\n",
      "üìà Collecting data for plotting...\n",
      "\n",
      "‚ú® Plotting successful. Image saved as: Combined_Energy_Analysis_Plot.png\n",
      "\n",
      "‚ú® Process completed: Aggregation and Plotting finished.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import matplotlib.pyplot as plt # Import for plotting\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 0. GLOBAL CONFIGURATION\n",
    "# ==============================================================================\n",
    "\n",
    "# Define the ligands used in the study for coloring and legend\n",
    "LIGANDS = ['Fe', 'Ga'] \n",
    "\n",
    "# Define which metrics (columns) should be plotted from the aggregated data.\n",
    "# Options: '[EELEC]', '[EVDW]', '[ETOTAL]'\n",
    "METRICS_TO_PLOT = ['[EELEC]', '[EVDW]'] \n",
    "\n",
    "# 1. VARIABLE PARA RANGO DEL EJE Y (Y-AXIS RANGE VARIABLE)\n",
    "# Define el rango [min, max] para el eje Y (Energy). \n",
    "# Ejemplos: [-100, 0] para limitar. Usa None o un array vac√≠o para que Matplotlib lo determine autom√°ticamente.\n",
    "Y_LIMITS = [-155, 45] \n",
    "\n",
    "# Plot styling and labels\n",
    "PLOT_TITLE = \"Electrostatic (EELEC) \\& Van der Waals (EVDW) Energy Analysis\"\n",
    "Y_AXIS_LABEL = \"Energy (kcal/mol)\"\n",
    "# Bar colors (Fe metrics will be orangish, Ga metrics will be blueish)\n",
    "COLORS = {\n",
    "    'Fe[EELEC]': '#ff7f0e', # Dark Orange\n",
    "    'Fe[EVDW]': '#ffbb78', # Light Orange\n",
    "    'Ga[EELEC]': '#1f77b4', # Dark Blue\n",
    "    'Ga[EVDW]':  '#aec7e8', # Light Blue\n",
    "    'Fe[ETOTAL]': '#98df8a', # Light Green (if used)\n",
    "    'Ga[ETOTAL]': '#2ca02c', # Dark Green (if used)\n",
    "}\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# I. AGGREGATION PHASE FUNCTIONS\n",
    "# ==============================================================================\n",
    "\n",
    "def get_descriptive_name(config: Dict[str, List[Any]]) -> str:\n",
    "    \"\"\"\n",
    "    Generates a descriptive filename based on AND, OR, and NOT search terms.\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    if config['AND']:\n",
    "        parts.append(\"AND-\" + \"_\".join(config['AND']))\n",
    "    \n",
    "    if config['OR_GROUPS']:\n",
    "        or_names = []\n",
    "        for i, group in enumerate(config['OR_GROUPS']):\n",
    "            group_str = f\"OR{i+1}-\" + \"_\".join(group[:2]) \n",
    "            if len(group) > 2:\n",
    "                group_str += \"_etc\"\n",
    "            or_names.append(group_str)\n",
    "        parts.append(\"_\".join(or_names))\n",
    "        \n",
    "    if config['NOT']:\n",
    "        parts.append(\"NOT-\" + \"_\".join(config['NOT'][:3])) \n",
    "        if len(config['NOT']) > 3:\n",
    "            parts.append(\"_etc\")\n",
    "            \n",
    "    base_name = \"_\".join(parts)\n",
    "    base_name = re.sub(r'[^\\w\\-]', '_', base_name)\n",
    "    \n",
    "    return base_name if base_name else \"Empty_Query\"\n",
    "\n",
    "\n",
    "def matches_boolean_query(filename: str, config: Dict[str, List[Any]]) -> bool:\n",
    "    \"\"\"\n",
    "    Checks if a filename meets the boolean logic: \n",
    "    (AND) AND (one option from EACH OR group) AND (NONE of NOT)\n",
    "    \"\"\"\n",
    "    name_lower = filename.lower()\n",
    "    and_condition = all(k.lower() in name_lower for k in config['AND'])\n",
    "    \n",
    "    or_groups_condition = True\n",
    "    if config['OR_GROUPS']:\n",
    "        for group in config['OR_GROUPS']:\n",
    "            group_matched = any(k.lower() in name_lower for k in group)\n",
    "            if not group_matched:\n",
    "                or_groups_condition = False\n",
    "                break\n",
    "    \n",
    "    not_condition = not any(k.lower() in name_lower for k in config['NOT'])\n",
    "    \n",
    "    return and_condition and or_groups_condition and not_condition\n",
    "\n",
    "\n",
    "def analyze_and_combine_csvs(folder_path=\".\") -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Processes multiple search configurations, filters, combines, calculates statistics, \n",
    "    saves a file for each configuration, and returns a map of config NAME to filepath.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. DEFINITION OF MULTIPLE GROUPS (16 configurations defined by the user)\n",
    "    # CADA DICCIONARIO ES UNA AGRUPACI√ìN QUE GENERAR√Å UN ARCHIVO CSV\n",
    "    # -------------------------------------------------------------------------\n",
    "    SEARCH_CONFIGS = [\n",
    "        { 'NAME': \"Fe-FeGa_ARG_HEM\", 'AND': [\"HH\"], 'OR_GROUPS': [[\"_FE_\", \"_FEGA_\"], [\"104\", \"844\"], [\"1481\", \"1483\"]], 'NOT': [] },\n",
    "        { 'NAME': \"Ga-GaFe_ARG_HEM\", 'AND': [\"HH\"], 'OR_GROUPS': [[\"_GA_\", \"_GAFE_\"], [\"104\", \"844\"], [\"1481\", \"1483\"]], 'NOT': [] },\n",
    "        { 'NAME': \"Fe-FeGa_ARG_MET\", 'AND': [\"HH\"], 'OR_GROUPS': [[\"_FE_\", \"_FEGA_\"], [\"104\", \"844\"], [\"1482\", \"1484\"]], 'NOT': [] },\n",
    "        { 'NAME': \"Ga-GaFe_ARG_MET\", 'AND': [\"HH\"], 'OR_GROUPS': [[\"_GA_\", \"_GAFE_\"], [\"104\", \"844\"], [\"1482\", \"1484\"]], 'NOT': [] },\n",
    "        { 'NAME': \"Fe-FeGa_TRP_HEM\", 'AND': [\"HH\"], 'OR_GROUPS': [[\"_FE_\", \"_FEGA_\"], [\"107\", \"847\"], [\"1481\", \"1483\"]], 'NOT': [] },\n",
    "        { 'NAME': \"Ga-GaFe_TRP_HEM\", 'AND': [\"HH\"], 'OR_GROUPS': [[\"_GA_\", \"_GAFE_\"], [\"107\", \"847\"], [\"1481\", \"1483\"]], 'NOT': [] },\n",
    "        { 'NAME': \"Fe-FeGa_TRP_MET\", 'AND': [\"HH\"], 'OR_GROUPS': [[\"_FE_\", \"_FEGA_\"], [\"107\", \"847\"], [\"1482\", \"1484\"]], 'NOT': [] },\n",
    "        { 'NAME': \"Ga-GaFe_TRP_MET\", 'AND': [\"HH\"], 'OR_GROUPS': [[\"_GA_\", \"_GAFE_\"], [\"107\", \"847\"], [\"1482\", \"1484\"]], 'NOT': [] },\n",
    "        { 'NAME': \"Fe-FeGa_HIS-A_HEM\", 'AND': [\"HH\"], 'OR_GROUPS': [[\"_FE_\", \"_FEGA_\"], [\"108\", \"848\"], [\"1481\", \"1483\"]], 'NOT': [] },\n",
    "        { 'NAME': \"Ga-GaFe_HIS-A_HEM\", 'AND': [\"HH\"], 'OR_GROUPS': [[\"_GA_\", \"_GAFE_\"], [\"108\", \"848\"], [\"1481\", \"1483\"]], 'NOT': [] },\n",
    "        { 'NAME': \"Fe-FeGa_HIS-A_MET\", 'AND': [\"HH\"], 'OR_GROUPS': [[\"_FE_\", \"_FEGA_\"], [\"108\", \"848\"], [\"1482\", \"1484\"]], 'NOT': [] },\n",
    "        { 'NAME': \"Ga-GaFe_HIS-A_MET\", 'AND': [\"HH\"], 'OR_GROUPS': [[\"_GA_\", \"_GAFE_\"], [\"108\", \"848\"], [\"1482\", \"1484\"]], 'NOT': [] },\n",
    "        { 'NAME': \"Fe-FeGa_HIS-B_HEM\", 'AND': [\"HH\"], 'OR_GROUPS': [[\"_FE_\", \"_FEGA_\"], [\"270\", \"1010\"], [\"1481\", \"1483\"]], 'NOT': [] },\n",
    "        { 'NAME': \"Ga-GaFe_HIS-B_HEM\", 'AND': [\"HH\"], 'OR_GROUPS': [[\"_GA_\", \"_GAFE_\"], [\"270\", \"1010\"], [\"1481\", \"1483\"]], 'NOT': [] },\n",
    "        { 'NAME': \"Fe-FeGa_HIS-B_MET\", 'AND': [\"HH\"], 'OR_GROUPS': [[\"_FE_\", \"_FEGA_\"], [\"270\", \"1010\"], [\"1482\", \"1484\"]], 'NOT': [] },\n",
    "        { 'NAME': \"Ga-GaFe_HIS-B_MET\", 'AND': [\"HH\"], 'OR_GROUPS': [[\"_GA_\", \"_GAFE_\"], [\"270\", \"1010\"], [\"1482\", \"1484\"]], 'NOT': [] },\n",
    "    ]\n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "    generated_files = {}\n",
    "\n",
    "    search_pattern_csv = os.path.join(folder_path, \"*.csv\")\n",
    "    all_csv_files = glob.glob(search_pattern_csv)\n",
    "\n",
    "    if not all_csv_files:\n",
    "        print(f\"‚ö†Ô∏è No CSV files found in the folder: {folder_path}\")\n",
    "        return {}\n",
    "\n",
    "    num_configs = len(SEARCH_CONFIGS)\n",
    "    print(f\"üîé Processing {num_configs} search configurations.\")\n",
    "\n",
    "    # Bucle principal para procesar CADA configuraci√≥n de b√∫squeda\n",
    "    for config_index, config in enumerate(SEARCH_CONFIGS):\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"CONFIGURATION {config_index + 1}/{num_configs}: {config['NAME']}\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        filtered_files = []\n",
    "        \n",
    "        # 2. Filter CSV files\n",
    "        for csv_file in all_csv_files:\n",
    "            file_name = os.path.basename(csv_file)\n",
    "            if matches_boolean_query(file_name, config):\n",
    "                filtered_files.append(csv_file)\n",
    "            \n",
    "        print(f\"‚úÖ Found {len(filtered_files)} files matching the condition.\")\n",
    "\n",
    "        if not filtered_files:\n",
    "            print(f\"‚ùå Configuration {config['NAME']} found no files. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        # Print list of included files for verification\n",
    "        print(\"\\nFiles included in this group:\")\n",
    "        for f in filtered_files:\n",
    "            print(f\"    - {os.path.basename(f)}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "\n",
    "        # 3. Combine DataFrames\n",
    "        try:\n",
    "            dataframes = []\n",
    "            for f in filtered_files:\n",
    "                try:\n",
    "                    df = pd.read_csv(f)\n",
    "                    # Use the correct columns for analysis, even if they contain LIE_00001\n",
    "                    required_cols = ['LIE_00001[EELEC]', 'LIE_00001[EVDW]', '[ETOTAL]']\n",
    "                    \n",
    "                    # Ensure the dataframe has at least one of the required columns\n",
    "                    if not df.empty and any(col in df.columns for col in required_cols):\n",
    "                        dataframes.append(df)\n",
    "                    elif df.empty:\n",
    "                        print(f\"    Info: Skipping empty file {os.path.basename(f)}.\")\n",
    "                    else:\n",
    "                        print(f\"    Warning: File {os.path.basename(f)} is missing required columns. Skipping.\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"    Error reading {os.path.basename(f)}: {e}\")\n",
    "                    \n",
    "            if not dataframes:\n",
    "                print(\"‚ùå No valid DataFrames to combine. Skipping.\")\n",
    "                continue\n",
    "                \n",
    "            df_combined = pd.concat(dataframes, ignore_index=True)\n",
    "            print(f\"‚úÖ DataFrames from {len(dataframes)} files combined. Total rows: {len(df_combined)}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error combining DataFrames: {e}\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        # 4. Calculate statistics\n",
    "        # Map the dataframe column names to the short names used for plotting\n",
    "        cols_analysis = {\n",
    "            'LIE_00001[EELEC]': '[EELEC]',\n",
    "            'LIE_00001[EVDW]': '[EVDW]',\n",
    "            '[ETOTAL]': '[ETOTAL]'\n",
    "        }\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for df_col, short_name in cols_analysis.items():\n",
    "            if df_col in df_combined.columns:\n",
    "                mean_val = df_combined[df_col].mean()\n",
    "                std_val = df_combined[df_col].std()\n",
    "                results.append([f\"{short_name} Media\", f\"{mean_val:.4f}\"])\n",
    "                results.append([f\"{short_name} Std\", f\"{std_val:.4f}\"])\n",
    "            else:\n",
    "                # Check for the short name if the LIE_ prefix is not present\n",
    "                if short_name in df_combined.columns:\n",
    "                    mean_val = df_combined[short_name].mean()\n",
    "                    std_val = df_combined[short_name].std()\n",
    "                    results.append([f\"{short_name} Media\", f\"{mean_val:.4f}\"])\n",
    "                    results.append([f\"{short_name} Std\", f\"{std_val:.4f}\"])\n",
    "                else:\n",
    "                    print(f\"   Warning: Column '{df_col}' or '{short_name}' not found. Skipping calculation.\")\n",
    "\n",
    "        \n",
    "        # 5. and 6. Generate descriptive name and save the file\n",
    "        output_base_name = get_descriptive_name(config)\n",
    "        output_csv_file = os.path.join(folder_path, f\"{output_base_name}_STATS.csv\")\n",
    "        \n",
    "        # Save CSV without stats first\n",
    "        df_combined.to_csv(output_csv_file, index=False)\n",
    "        \n",
    "        # 7. Insert results into the header\n",
    "        if results:\n",
    "            temp_file = output_csv_file + \".tmp\"\n",
    "            \n",
    "            # Format criteria for the header (more readable)\n",
    "            and_str = f\"AND: ({', '.join(config['AND'])})\"\n",
    "            not_str = f\"NOT: ({', '.join(config['NOT'])})\"\n",
    "            or_str_parts = []\n",
    "            for group in config['OR_GROUPS']:\n",
    "                or_str_parts.append(f\"({' OR '.join(group)})\")\n",
    "            or_str = f\"OR GROUPS: \" + \" AND \".join(or_str_parts)\n",
    "\n",
    "            # Prepare header lines as simple strings (NOT lists for csv.writer)\n",
    "            header_lines = [\n",
    "                f\"# GROUP: {config['NAME']}\",\n",
    "                f\"# Applied Criteria: {and_str} | {or_str} | {not_str}\", \n",
    "                f\"#--------------------------------------\",\n",
    "            ]\n",
    "            \n",
    "            # Consolidate statistics into a single, pipe-separated metadata string\n",
    "            metadata_parts = []\n",
    "            for label, value in results:\n",
    "                # Rename Spanish labels to English for consistency (Media -> Mean, Std -> Std)\n",
    "                english_label = label.replace(\" Media\", \" Mean\").replace(\" Std\", \" Std\")\n",
    "                metadata_parts.append(f\"{english_label} = {value}\")\n",
    "            \n",
    "            # **FIX: Use pipe '|' as delimiter for robust reading later**\n",
    "            stats_line = \"# STATS: \" + \" | \".join(metadata_parts)\n",
    "            header_lines.append(stats_line)\n",
    "            header_lines.append(\"#--------------------------------------\")\n",
    "            \n",
    "            # Perform header insertion using file write for clean metadata\n",
    "            # We open with newline='' to ensure correct newline handling for csv reader/writer\n",
    "            with open(output_csv_file, 'r', newline='') as infile, \\\n",
    "                 open(temp_file, 'w', newline='') as outfile:\n",
    "                \n",
    "                # Write header lines directly as strings\n",
    "                for line in header_lines:\n",
    "                    outfile.write(line + '\\n') \n",
    "                \n",
    "                # Copy original content (including data header) using csv module\n",
    "                csv.writer(outfile).writerows(csv.reader(infile))\n",
    "\n",
    "            # Replace original file\n",
    "            os.replace(temp_file, output_csv_file)\n",
    "            print(f\"   ‚úÖ Final file generated: {os.path.basename(output_csv_file)}\")\n",
    "            \n",
    "            # Save the generated file path for plotting phase\n",
    "            generated_files[config['NAME']] = output_csv_file\n",
    "            \n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Could not calculate statistics.\")\n",
    "            \n",
    "    return generated_files\n",
    "\n",
    "# ==============================================================================\n",
    "# II. PLOTTING PHASE FUNCTIONS\n",
    "# ==============================================================================\n",
    "\n",
    "def extract_stats_from_csv(file_path: str, metrics: List[str]) -> Dict[str, Tuple[float, float]]:\n",
    "    \"\"\"\n",
    "    Reads the mean and standard deviation (std) from the metadata header of the CSV file.\n",
    "    \n",
    "    Returns:\n",
    "        A dictionary mapping metric name to a (mean, std) tuple, e.g.,\n",
    "        {'[EELEC]': (mean_val, std_val)}\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    \n",
    "    # Generate the search keys based on the desired metrics\n",
    "    mean_keys = [f\"{m} Mean\" for m in metrics]\n",
    "    std_keys = [f\"{m} Std\" for m in metrics]\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                # Stop when the data header starts (i.e., when no longer a comment/metadata line)\n",
    "                if not line.startswith('#'):\n",
    "                    break\n",
    "                \n",
    "                # Find the STATS line\n",
    "                if line.startswith('# STATS:'):\n",
    "                    # Remove the prefix and split by ' | '\n",
    "                    stats_str = line.strip().replace('# STATS:', '').strip()\n",
    "                    parts = stats_str.split(' | ') \n",
    "                    \n",
    "                    # Parse each key=value pair\n",
    "                    stats_map = {}\n",
    "                    for part in parts:\n",
    "                        if '=' in part:\n",
    "                            key, value = part.split('=', 1)\n",
    "                            # Now, we ensure correct type conversion.\n",
    "                            try:\n",
    "                                stats_map[key.strip()] = float(value.strip())\n",
    "                            except ValueError as ve:\n",
    "                                print(f\"   Error converting value to float for {key.strip()}: {value.strip()}. Error: {ve}\")\n",
    "                                \n",
    "                    # Consolidate mean and std into the final data structure\n",
    "                    for metric in metrics:\n",
    "                        mean_label = f\"{metric} Mean\"\n",
    "                        std_label = f\"{metric} Std\"\n",
    "                        \n",
    "                        if mean_label in stats_map and std_label in stats_map:\n",
    "                            data[metric] = (stats_map[mean_label], stats_map[std_label])\n",
    "                        else:\n",
    "                            print(f\"   Warning: Missing data for {metric} in {os.path.basename(file_path)}\")\n",
    "                    return data\n",
    "                    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"   Error: File not found for plotting: {os.path.basename(file_path)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   Error parsing stats from {os.path.basename(file_path)}: {e}\")\n",
    "        \n",
    "    return data\n",
    "\n",
    "def generate_bar_chart(plot_groups: List[Dict[str, Any]], ligands: List[str], metrics_to_plot: List[str], generated_files: Dict[str, str]):\n",
    "    \"\"\"\n",
    "    Generates a grouped bar chart with error bars from the aggregated data.\n",
    "    \"\"\"\n",
    "    if not generated_files:\n",
    "        print(\"‚ùå Cannot generate chart: No files were successfully aggregated.\")\n",
    "        return\n",
    "\n",
    "    # 1. Collect all data\n",
    "    data_points = []\n",
    "    x_labels = []\n",
    "\n",
    "    print(\"\\nüìà Collecting data for plotting...\")\n",
    "\n",
    "    # Iterate through the desired groups for the X-axis (all groups are included now)\n",
    "    for group in plot_groups:\n",
    "        current_x_label = group['X_LABEL']\n",
    "        x_labels.append(current_x_label)\n",
    "        group_data = {}\n",
    "        is_group_valid = True\n",
    "        \n",
    "        # Iterate through the ligands (Fe, Ga) for the current X-axis group\n",
    "        for config_name in group['CONFIG_NAMES']:\n",
    "            \n",
    "            if config_name not in generated_files:\n",
    "                # If a file is missing, we invalidate the entire group for plotting\n",
    "                print(f\"   Warning: File for config '{config_name}' not found. Skipping plot group: {current_x_label}\")\n",
    "                is_group_valid = False\n",
    "                break\n",
    "                \n",
    "            file_path = generated_files[config_name]\n",
    "            stats = extract_stats_from_csv(file_path, metrics_to_plot)\n",
    "            \n",
    "            # DETERMINE LIGAND SAFELY:\n",
    "            ligand = None\n",
    "            try:\n",
    "                # Extract the part before the first hyphen and find the matching ligand\n",
    "                prefix = config_name.split('-')[0]\n",
    "                # Check for case-insensitive match (e.g., 'Fe' in config vs 'Fe' in LIGANDS)\n",
    "                ligand = next((L for L in ligands if L.lower() == prefix.lower()), None)\n",
    "            except Exception as e:\n",
    "                print(f\"   Error determining ligand from config name '{config_name}': {e}\")\n",
    "                \n",
    "            if ligand is None:\n",
    "                # This should not happen if config_names are correct, but handles unexpected data gracefully.\n",
    "                print(f\"   Error: Could not determine primary ligand (Fe or Ga) from config name: '{config_name}'. Skipping plot group: {current_x_label}\")\n",
    "                is_group_valid = False\n",
    "                break # Skip the entire group if the ligand cannot be identified\n",
    "            \n",
    "            # Store the extracted stats\n",
    "            for metric, (mean, std) in stats.items():\n",
    "                key = f\"{ligand}{metric}\" # e.g., 'Fe[EELEC]'\n",
    "                group_data[key] = {'mean': mean, 'std': std}\n",
    "        \n",
    "        # Only append data if the entire group passed checks\n",
    "        if is_group_valid and group_data:\n",
    "            data_points.append(group_data)\n",
    "        else:\n",
    "            # If the group was invalid or empty, we append None as a placeholder\n",
    "            data_points.append(None)\n",
    "\n",
    "\n",
    "    # Filter out any groups that were skipped (i.e., where data_points item is None)\n",
    "    # This also ensures valid_x_labels matches the data_points indices.\n",
    "    valid_data_points = [dp for dp in data_points if dp is not None]\n",
    "    valid_x_labels = [x_labels[i] for i, dp in enumerate(data_points) if dp is not None]\n",
    "    \n",
    "    if not valid_data_points:\n",
    "        print(\"‚ùå All plot groups were empty or had missing files. Chart generation failed.\")\n",
    "        return\n",
    "        \n",
    "    # 2. Prepare plot data structure\n",
    "    \n",
    "    # Total number of unique bars per X-axis group (e.g., 2 ligands * 2 metrics = 4 bars)\n",
    "    num_bars_per_group = len(ligands) * len(metrics_to_plot)\n",
    "    \n",
    "    # Width of a single bar\n",
    "    bar_width = 0.8 / num_bars_per_group \n",
    "    \n",
    "    # List of all keys in the order they should appear (Fe metrics, then Ga metrics)\n",
    "    plot_keys = [f\"{L}{M}\" for L in ligands for M in metrics_to_plot]\n",
    "    \n",
    "    # X positions for each group (0, 1, 2, ...) based on valid groups\n",
    "    x = range(len(valid_x_labels))\n",
    "    \n",
    "    # Mayor tama√±o de figura para una mejor visualizaci√≥n\n",
    "    fig, ax = plt.subplots(figsize=(16, 8)) \n",
    "    \n",
    "    # 3. Plotting loop\n",
    "    \n",
    "    # Keep track of which bar key corresponds to which legend label\n",
    "    handles = []\n",
    "    labels = []\n",
    "    \n",
    "    for i, key in enumerate(plot_keys):\n",
    "        # Calculate the X position for this specific bar type (e.g., Fe[EELEC])\n",
    "        x_pos = [p + i * bar_width - (num_bars_per_group - 1) * bar_width / 2 for p in x]\n",
    "        \n",
    "        # Extract means and stds for this key across all X-axis groups\n",
    "        means = [d.get(key, {}).get('mean', 0) for d in valid_data_points]\n",
    "        stds = [d.get(key, {}).get('std', 0) for d in valid_data_points]\n",
    "\n",
    "        # Mapeo de nombres de ligandos y m√©tricas para la leyenda\n",
    "        # [CORRECCI√ìN 3]: Usamos formato LaTeX para los super√≠ndices (e.g., r\"$Fe^{3+}$\")\n",
    "        METRIC_MAP = {'[EELEC]': r\"E(\\mathrm{elec})\", \"[EVDW]\": r\"E(\\mathrm{VdW})\", '[ETOTAL]': r\"E(\\mathrm{total})\"}\n",
    "        LIGAND_MAP = {'Fe': r\"\\mathrm{Fe}^{3+}\", 'Ga': r\"\\mathrm{Ga}^{3+}\"}\n",
    "\n",
    "\n",
    "        # Determine color and label for the legend\n",
    "        # Handle both 'Fe[EELEC]' and 'GA[EVDW]' style keys\n",
    "        ligand_name = next((L for L in ligands if key.upper().startswith(L.upper())), None)\n",
    "        if ligand_name:\n",
    "            metric = key[len(ligand_name):]\n",
    "        else:\n",
    "            ligand_name = '??'\n",
    "            metric = key # Fallback\n",
    "\n",
    "        color = COLORS.get(key, 'gray')\n",
    "\n",
    "        # Traducci√≥n de la etiqueta\n",
    "        translated_ligand = LIGAND_MAP.get(ligand_name, ligand_name)\n",
    "        translated_metric = METRIC_MAP.get(metric, metric)\n",
    "\n",
    "        # Nueva etiqueta en formato \"E(elec) Fe3+\"\n",
    "        # [CORRECCI√ìN 4]: La etiqueta final debe combinar las partes con mathtext.\n",
    "        label = fr\"$ {translated_metric}\\ {translated_ligand} $\"\n",
    "\n",
    "        # Plot the bars with error bars\n",
    "        bar_handle = ax.bar(\n",
    "            x_pos, \n",
    "            means, \n",
    "            bar_width, \n",
    "            yerr=stds, \n",
    "            label=label, \n",
    "            color=color, \n",
    "            capsize=5, \n",
    "            error_kw={'capthick': 1.5}\n",
    "        )\n",
    "        \n",
    "        # Collect handles for the legend\n",
    "        if label not in labels:\n",
    "            handles.append(bar_handle[0]) \n",
    "            labels.append(label)\n",
    "\n",
    "    # 4. Final plot customization\n",
    "    \n",
    "    # Set X-axis ticks to the center of the bar groups\n",
    "    ax.set_xticks(x)\n",
    "\n",
    "    # Aplica la negrita aqu√≠ a las etiquetas del eje X, sin usar \\textbf{} en la cadena Mathtext.\n",
    "    ax.set_xticklabels(valid_x_labels, rotation=45, ha=\"right\", fontsize=12, fontweight='bold', color=\"black\")\n",
    "\n",
    "\n",
    "    ax.tick_params(axis='y', which='major', labelsize=12)\n",
    "    for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "        label.set_fontweight(\"bold\")\n",
    "    \n",
    "\n",
    "    ax.set_title(PLOT_TITLE, fontweight='bold', fontsize=16) \n",
    "    \n",
    "    # Eje Y: tama√±o 14 y negrita\n",
    "    ax.set_ylabel(Y_AXIS_LABEL, fontweight='bold', fontsize=14)\n",
    "    \n",
    "    if Y_LIMITS and len(Y_LIMITS) == 2:\n",
    "        ax.set_ylim(Y_LIMITS)\n",
    "    \n",
    "    ax.legend(\n",
    "        loc='best', \n",
    "        handles=handles, \n",
    "        labels=labels, \n",
    "        fancybox=True,      \n",
    "        framealpha=0.9,     \n",
    "        shadow=True,        \n",
    "        fontsize=14\n",
    "    )\n",
    "    \n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "    \n",
    "    # Save the figure\n",
    "    plot_filename = \"Combined_Energy_Analysis_Plot.png\"\n",
    "    plt.savefig(plot_filename, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"\\n‚ú® Plotting successful. Image saved as: {plot_filename}\")\n",
    "\n",
    "\n",
    "# --- Main Execution Block ---\n",
    "\n",
    "# 1. Define the 8 main plot groups (X-axis labels) and map them to the \n",
    "#    16 generated file configuration names (Fe and Ga versions).\n",
    "PLOT_GROUPS = [\n",
    "    # [CORRECCI√ìN APLICADA]: Se elimina \\textbf{} de las cadenas Mathtext (eje X)\n",
    "    # La negrita se aplica externamente con 'fontweight' en ax.set_xticklabels.\n",
    "    {\n",
    "        'X_LABEL': r\"$\\text{Arg(104)} \\rightarrow \\text{HEM}$\",\n",
    "        'CONFIG_NAMES': [\"Fe-FeGa_ARG_HEM\", \"Ga-GaFe_ARG_HEM\"]\n",
    "    },\n",
    "    {\n",
    "        'X_LABEL': r\"$\\text{Arg(104)} \\rightarrow \\text{Fe/Ga}$\",\n",
    "        'CONFIG_NAMES': [\"Fe-FeGa_ARG_MET\", \"Ga-GaFe_ARG_MET\"]\n",
    "    },\n",
    "    {\n",
    "        'X_LABEL': r\"$\\text{Trp(107)} \\rightarrow \\text{HEM}$\",\n",
    "        'CONFIG_NAMES': [\"Fe-FeGa_TRP_HEM\", \"Ga-GaFe_TRP_HEM\"]\n",
    "    },\n",
    "    {\n",
    "        'X_LABEL': r\"$\\text{Trp(107)} \\rightarrow \\text{Fe/Ga}$\",\n",
    "        'CONFIG_NAMES': [\"Fe-FeGa_TRP_MET\", \"Ga-GaFe_TRP_MET\"]\n",
    "    },\n",
    "    {\n",
    "        'X_LABEL': r\"$\\text{His}\\alpha\\text{(108)} \\rightarrow \\text{HEM}$\",\n",
    "        'CONFIG_NAMES': [\"Fe-FeGa_HIS-A_HEM\", \"Ga-GaFe_HIS-A_HEM\"]\n",
    "    },\n",
    "    {\n",
    "        'X_LABEL': r\"$\\text{His}\\alpha\\text{(108)} \\rightarrow \\text{Fe/Ga}$\",\n",
    "        'CONFIG_NAMES': [\"Fe-FeGa_HIS-A_MET\", \"Ga-GaFe_HIS-A_MET\"]\n",
    "    },\n",
    "    {\n",
    "        'X_LABEL': r\"$\\text{His}\\beta\\text{(270)} \\rightarrow \\text{HEM}$\",\n",
    "        'CONFIG_NAMES': [\"Fe-FeGa_HIS-B_HEM\", \"Ga-GaFe_HIS-B_HEM\"]\n",
    "    },\n",
    "    {\n",
    "        'X_LABEL': r\"$\\text{His}\\beta\\text{(270)} \\rightarrow \\text{Fe/Ga}$\",\n",
    "        'CONFIG_NAMES': [\"Fe-FeGa_HIS-B_MET\", \"Ga-GaFe_HIS-B_MET\"]\n",
    "    },\n",
    "]\n",
    "\n",
    "# Run Phase 1: Aggregation\n",
    "generated_files = analyze_and_combine_csvs()\n",
    "\n",
    "# Run Phase 2: Plotting\n",
    "generate_bar_chart(PLOT_GROUPS, LIGANDS, METRICS_TO_PLOT, generated_files)\n",
    "\n",
    "print(\"\\n‚ú® Process completed: Aggregation and Plotting finished.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
